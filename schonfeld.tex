\documentclass[presentation]{beamer}

% packages
\usepackage{amsmath,amsthm,comment,listings,url,xspace}
\usepackage{array,graphicx,amssymb,psfrag}
\usepackage{algorithm,algorithmicx,algpseudocode}
% \usepackage[dvipsnames]{xcolor}

\usepackage{epstopdf}
\epstopdfsetup{update}

\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\pgfplotsset{every axis legend/.append style={%
cells={anchor=west}}
}
\usetikzlibrary{arrows}
\tikzset{>=stealth'}
\pgfplotsset{width=12cm}

% where to find stuff
\newcommand{\home}{../../papers/cvxjl}
\newcommand{\talks}{.}
\newcommand{\figures}{./figures}
\input \talks/defs.tex
\input \talks/formatting.tex
\newcommand{\citet}[1]{{\footnotesize{\textmd{[#1]}}}}

% definitions for just this talk
% \newcommand{\juliaopt}{\textsc{JuliaOpt}\xspace}
% \newcommand{\convex}{\textsc{Convex}\xspace}
% \newcommand{\lrm}{\textsc{LowRankModels}\xspace}
\newcommand{\juliaopt}{JuliaOpt\xspace}
\newcommand{\convex}{Convex\xspace}
\newcommand{\lrm}{LowRankModels\xspace}
% \newcommand{\multi}{\texttt{MultiConvex.jl}}

\mode<handout>
%\mode<presentation>
{
\usetheme{default}
}
\setbeamertemplate{footline}[frame number]

\bibliographystyle{alpha}

\title{Convex Optimization}

\date[Schonfeld Quantitative, September 26 2017]{\textcolor{blue}{Schonfeld Quantitative, September 26 2017}}
% \author{{\bf Madeleine Udell} \\
% Cornell University
% % with Karanveer Mohan, David Zeng, Jenny Hong, \\
% % Steven Diamond, and Stephen Boyd\\[1ex]
% %Institute for Computational and Mathematical Engineering,
% %Computational and Mathematical Engineering,
% ACC 2017
% }
\author[M.~Udell, Cornell. \textit{Optimization in Julia.}]{%
Madeleine Udell \\[1ex]
Operations Research and Information Engineering\\
Cornell University\\
}
% \vspace{.4in}
% Based on joint work with \\
% with Karanveer Mohan, David Zeng, Jenny Hong, \\
% Steven Diamond, and Stephen Boyd; \\
% Miles Lubin, Iain Dunning, and Joey Huchette.}

\begin{document}

\begin{frame}
\titlepage
\end{frame}

% \begin{frame}{Outline}
% \tableofcontents
% \end{frame}

\section{Optimization}

\begin{frame}{What is an optimization problem?}

the optimization contract:
\bit
\item you give me a function, and I'll find you its minimum
\hbox{\hspace{.2in} \includegraphics[scale=0.4]{\figures/nonconvex.pdf}}
\vspace{-.45in}
\pause\item why optimize?

\bit
\item fit a model to data (\eg, understand customer preferences)
\item make predictions (\eg, image recognition)
\item maximize revenue (\eg, airline pricing)
\item maximize investment returns (\eg, quant finance)
\item design a control system (\eg, autopilot)
\item \ldots
\eit

\eit
\end{frame}

\begin{frame}{How to find the minimum}

\hbox{\hspace{.4in} \includegraphics[scale=0.4]{\figures/nonconvex.pdf}}

\vspace{-.2in}
how to find the minimum? \pause
\bit
\pause \item set derivative to zero \pause \ldots derivative has an analytical formula
\pause \item gradient descent / backprop \pause \ldots if $f$ is differentiable
\pause \item other fancy optimization methods \pause \ldots where they apply
\pause \item point \pause \ldots if I can plot problem in 2D or 3D
\eit

\pause \textbf{key question:} what do I know about the problem?

\end{frame}

% \begin{frame}[fragile]{How to give a function}
%
% \bit
% \item as a plot
% \begin{centering}\includegraphics[scale=0.2]{\figures/nonconvex.pdf} \end{centering}
%
% \item as an oracle
%
% \cfh[.15]{oracle.png}
%
% \item as a type
%
% \cfh[.3]{f_as_type.png}
%
% \eit
%
% \end{frame}

% \begin{frame}{How to give a function}
%
% \textbf{demo:}
% \begin{center}
% \url{https://github.com/madeleineudell/schoenfeld/Convex-tutorial.ipynb}
% \end{center}
%
% \end{frame}

\section{Convexity}

\begin{frame}{What is an optimization problem?}

\[
\begin{array}{ll}
\mbox{minimize}  & f_0(x) \\
\mbox{subject to} & f_i(x) \leq 0, \quad i=1, \ldots, m_1\\
& h_i(x) = 0, \quad i=1, \ldots, m_2\\
\end{array}
\]

\bit
\item problem variable $x \in \reals^n$
\item objective $f_0$
\item inequality constraints $f_i$
\item equality constraints $h_i$
\eit

\end{frame}

\begin{frame}{Convex optimization}

general optimization problems are hard
\bit
\item local minima, saddle points
\item can take exponential time to solve
\eit
\vfill
convex optimization problems are easy
\bit
\item all minima are global
\item fast, global convergence
\item can prove we found a solution
\item models a wide variety of real problems
\eit

\end{frame}

\begin{frame}{Convexity}

$f$ is \textbf{convex} if for all $\theta \in [0,1]$
$$
f(\theta x + (1-\theta)y ) \leq \theta f(x) + (1-\theta) f(y)
$$
\vspace{-.5in}
\cfh[.5]{chord.png}
\vspace{-.5in}
equivalently,
\bit
\item $f$ has nonnegative (upward) curvature
\item the graph of $f$ never lies above its chords
\item $f'' \geq 0$ (if $f$ is differentiable)
% \item epigraph $\{(x,t): f(x) \leq t\}$ is a convex set
%     \bit \item implies sublevel sets $\{x: f(x) \leq \alpha\}$ are convex sets \eit
\eit

% * $f$ is **concave** iff $-f$ is convex
% * $f$ is **affine** iff $f$ is both convex and concave

\end{frame}

% \begin{frame}{Convexity}
%
% A set $S$ is convex if for any $x$,$y \in \mathcal C$
% \[
% \theta x + (1-\theta) y \in \mathcal C, \qquad \theta \in [0,1]
% \]
% \vfill
% A function $f: \mathcal C$ is convex if for any $x$,$y \in \mathcal C$
% \[
% f(\theta x + (1-\theta) y) \leq \theta f(x) + (1-\theta)f(y), \qquad \theta \in [0,1]
% \]
% \vfill
% For convex functions, averages of ``good'' solutions only get better
%
% \end{frame}

\begin{frame}{Convex optimization}

convex optimization problem:
\[
\begin{array}{ll}
\mbox{minimize}  & f_0(x) \\
\mbox{subject to} & f_i(x) \leq 0, \quad i=1, \ldots, m_1\\
& h_i(x) = 0, \quad i=1, \ldots, m_2\\
\end{array}
\]
where
\bit
\item objective $f_0$ is convex
\item inequality constraints $f_i$ are convex
\item equality constraints $h_i$ are affine
\eit

\end{frame}

% \begin{frame}{How to give a function}
%
% moral:
% \bit
% \item a function is a type
% \item on which various operations are defined
% \item which can be used to solve optimization problems
% \eit
%
% advantages:
% \bit
% \item easy to understand
% \item easy to reuse code
% \item easy to extend by adding new methods
% \eit
% \end{frame}

\section{\convex}

\begin{frame}{\convex in action}

\textbf{demo:}
\begin{center}
\url{https://github.com/madeleineudell/schoenfeld/Convex-tutorial.ipynb}
\end{center}

\end{frame}

\section{Flexibility matters: portfolio optimization}

\begin{frame}{Portfolio optimization}

\textbf{demo:}
\begin{center}
\url{https://github.com/madeleineudell/schoenfeld/Convex-tutorial.ipynb}
\end{center}

\end{frame}

\section{Certifying convexity}

\begin{frame}[fragile]{Disciplined convex programming}
\textbf{Disciplined convex programming} (DCP) \citet{Grant, Boyd \& Ye, 2006}
provides a set of simple inductive rules to verify convexity:
\bit
\item $f \circ g(x)$ is convex in $x$ if
    \bit
    \item $f$ is convex nondecreasing and $g$ is convex
    \item $f$ is convex nonincreasing and $g$ is concave
    \eit
    \cf, the chain rule:
    \[
    (f \circ g)''(x) = f''(g(x))(g(x))^2 + f'(g(x))g''(x)
    \]
\pause
\item $f \circ g(x)$ is concave in $x$ if $-f \circ g(x)$ is convex
\item $f \circ g(x)$ is affine if it is both convex and concave
    % \bit
    % \item $f$ is concave nondecreasing and $g$ is concave
    % \item $f$ is concave nonincreasing and $g$ is convex
    % \eit
\eit

A function is \textbf{DCP} if its convexity (or concavity) can be inferred from these composition rules.

\pause (\textbf{N.B.} a function that is not DCP may still be convex)

\end{frame}

\begin{frame}{DCP: demo}

\textbf{demo:}
\begin{center}
\url{https://github.com/madeleineudell/schoenfeld/Convex-tutorial.ipynb}
\end{center}

\end{frame}

\section{Models and solvers}

\begin{frame}{Structure determines solvers}

How should we solve this problem?
\bit
\item LP solver?
\item conic solver?
\item nonlinear derivative based solver?
\item operator splitting?
\eit
\pause
\textbf{What do we know about this problem's structure?}

\end{frame}

\begin{frame}{Structure}

useful kinds of structure:
\bit
\item is the problem convex?
\item is the problem representable in some standard form?
\bit
\item convex: LP, QP, SOCP, SDP, \ldots
\item nonconvex: MILP, MISOCP \ldots
\eit
\item is the problem smooth?
% \item is the problem separable?
\item \ldots
\eit

\end{frame}

\begin{frame}{Optimization in Julia}

model specifies structure; solvers exploit structure
\bit
\item model (\eg, JuMP or Convex)
\item glue (MathProgBase)
\item solvers (\eg, GLKP, Gurobi, Mosek, ECOS, \ldots)
\eit

JuliaOpt curates all these solvers: \url{http://www.juliaopt.org/}

\end{frame}
\begin{frame}{Convex optimization modeling tools}

many choices for convex optimization modeling!
\bit
\item Convex.jl (Julia; this talk)
\item CVX (Matlab)
\item CVXPY (Python)
\item CVXR (R)
\eit

\end{frame}

\begin{frame}{Summary}

convex optimization provides
\bit
\item flexible modeling
\item fast, efficient, reliable algorithms
\item guaranteed solutions
\eit

\end{frame}

\end{document}
